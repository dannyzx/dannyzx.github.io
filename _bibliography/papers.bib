@article{d2023learning,
  title={Learning Active Subspaces and Discovering Important Features with Gaussian Radial Basis Functions Neural Networks},
  author={D'Agostino, Danny and Ilievski, Ilija and Shoemaker, Christine Annette},
  journal={arXiv preprint arXiv:2307.05639},
  year={2023},
abstract={Providing a model that achieves a strong predictive performance and at the same time is interpretable by humans is one of the most difficult challenges in machine learning research due to the conflicting nature of these two objectives. To address this challenge, we propose a modification of the Radial Basis Function Neural Network model by equipping its Gaussian kernel with a learnable precision matrix. We show that precious information is contained in the spectrum of the precision matrix that can be extracted once the training of the model is completed. In particular, the eigenvectors explain the directions of maximum sensitivity of the model revealing the active subspace and suggesting potential applications for supervised dimensionality reduction. At the same time, the eigenvectors highlight the relationship in terms of absolute variation between the input and the latent variables, thereby allowing us to extract a ranking of the input variables based on their importance to the prediction task enhancing the model interpretability. We conducted numerical experiments for regression, classification, and feature selection tasks, comparing our model against popular machine learning models and the state-of-the-art deep learning-based embedding feature selection techniques. Our results demonstrate that the proposed model does not only yield an attractive prediction performance with respect to the competitors but also provides meaningful and interpretable results that potentially could assist the decision-making process in real-world applications. A PyTorch implementation of the model is available on GitHub at the following link https://github.com/dannyzx/GRBF-NNs.}
}

@misc{dagostino2023generative,
      title={Generative Models for Anomaly Detection and Design-Space Dimensionality Reduction in Shape Optimization}, 
      author={Danny D'Agostino},
  journal={arXiv preprint arXiv:2308.04051},
      year={2023},
abstract={Our work presents a novel approach to shape optimization, that has the twofold objective to improve the efficiency of global optimization algorithms while promoting the generation of high-quality designs during the optimization process free of geometrical anomalies. This is accomplished by reducing the number of the original design variables defining a new reduced subspace where the geometrical variance is maximized and modeling the underlying generative process of the data via probabilistic linear latent variable models such as Factor Analysis and Probabilistic Principal Component Analysis. We show that the data follows approximately a Gaussian distribution when the shape modification method is linear and the design variables are sampled uniformly at random, due to the direct application of the central limit theorem. The model uncertainty is measured in terms of Mahalanobis distance, and the paper demonstrates that anomalous designs tend to exhibit a high value of this metric. This enables the definition of a new optimization model where anomalous geometries are penalized and consequently avoided during the optimization loop. The procedure is demonstrated for hull shape optimization of the DTMB 5415 model, extensively used as an international benchmark for shape optimization problems. The global optimization routine is carried out using Bayesian Optimization and the DIRECT algorithm. From the numerical results, the new framework improves the convergence of global optimization algorithms, while only designs with high-quality geometrical features are generated through the optimization routine thereby avoiding the wastage of precious computationally expensive simulations.}
}


@Article{jmse11061220,
AUTHOR = {D’Agostino, Danny and Diez, Matteo and Felli, Mario and Serani, Andrea},
TITLE = {PIV Snapshot Clustering Reveals the Dual Deterministic and Chaotic Nature of Propeller Wakes at Macro- and Micro-Scales},
JOURNAL = {Journal of Marine Science and Engineering},
VOLUME = {11},
YEAR = {2023},
NUMBER = {6},
ARTICLE-NUMBER = {1220},
URL = {https://www.mdpi.com/2077-1312/11/6/1220},
ISSN = {2077-1312},
ABSTRACT = {This study investigates the underlying mechanisms governing the evolution of tip vortices in the far field of a naval propeller wake. To achieve this, a novel approach utilizing data clustering applied to particle image velocimetry snapshots is employed. The clustering of data is carried out using the k-means algorithm, with the optimal number of clusters determined by evaluating two metrics: the within-cluster sum of squares and the average silhouette. The clustering of phase-locked propeller wake data is focused on the vorticity associated with the regions containing tip vortices. Additionally, techniques such as proper orthogonal decomposition, t-distributed stochastic neighbor embedding, and kernel density estimation are employed to visually represent the data clusters in a two-dimensional space, facilitating their assessment and subsequent discussion. This paper shows how the application of data clustering enables a comprehensive understanding of the complex mechanisms driving the dynamics of propeller wake vortices in both the transitional and far fields. Specifically, it reveals the dual nature of the propeller wake flow, characterized by deterministic and chaotic behavior at macro- and micro-scales.},
DOI = {10.3390/jmse11061220}
}

@article{d2022efficient,
  title={An Efficient Global Optimization Algorithm with Adaptive Estimates of the Local Lipschitz Constants},
  author={D'Agostino, Danny},
  journal={arXiv preprint arXiv:2211.04129},
  year={2022},
abstract={In this work, we present a new deterministic partition-based Global Optimization (GO) algorithm that uses estimates of the local Lipschitz constants associated with different sub-regions of the domain of the objective function. The estimates of the local Lipschitz constants associated with each partition are the result of adaptively balancing the global and local information obtained so far from the algorithm, given in terms of absolute slopes. We motivate a coupling strategy with local optimization algorithms to accelerate the convergence speed of the proposed approach. In the end, we compare our approach HALO (Hybrid Adaptive Lipschitzian Optimization) with respect to popular GO algorithms using hundreds of test functions. From the numerical results, the performance of HALO is very promising and can extend our arsenal of efficient procedures for attacking challenging real-world GO problems. The Python code of HALO is publicly available on GitHub https://github.com/dannyzx/HALO.}
}

@article{d2022time,
  title={Time-series forecasting for ships maneuvering in waves via recurrent-type neural networks},
  author={D’Agostino, Danny and Serani, Andrea and Stern, Frederick and Diez, Matteo},
  journal={Journal of Ocean Engineering and Marine Energy},
  volume={8},
  number={4},
  pages={479--487},
  year={2022},
  publisher={Springer}
}